SCC Wastewater Rt:
==================

## **Model description:** 
The Santa Clara County Wastewater $R_t$ model is derived from the work of [Huisman et al.](https://doi.org/10.1289/EHP10050), but includes several modifications. The model and others like it first fit a smooth curve to the normalized wastewater data to remove noise and recover the underlying trend of interest before converting the wastewater concentrations into an estimated time series of infection events by deconvolving the smoothed wastewater signal with an estimate of the shedding load distribution - i.e., the average quantity of target genes shed over time since infection. Once the time series of infection events has been estimated, $R_t$ can be recovered based on an estimate of the generation interval distribution - i.e., average probability of an infected individual producing secondary infections over time - using standard renewal equation methods. A description of the SCC approach, highlighting unique features, follows:

1. **Smoothing:** Underlying trends in wastewater concentrations are recovered by fitting an adaptive spline (`bs = 'ad'` in `mgcv`'s `gam()` function) on the log scale, accounting for day of week effects and AR1 correlation in fitted residuals. Current settings allow for knots in the spline every 2 weeks (argument `k`), while the overall smoothness of the function (penalty for spline coefficient magnitudes) may change its trajectory on a quarterly basis (argument `m`). If nondetects are present in the data, a Tobit model is fit, which treats these as censored observations somewhere below $0.99 ~ \times$ the lowest observed value, allowing the SCC WW Rt model to acommodate 0 values in its log-transformed wastewater variable. Once the smooth curve has been fit, outliers are identified as observations which would not be expected to be observed in 95% of datasets generated under the smooth model, i.e. those with probabilities of occurrence $<0.05/T$ under the smoothing model, where $T$ is the number of timepoints in the input data. Any outliers flagged by this criterion are resampled according to the smooth fit, preserving the sign of their residual, and the process of fitting a smooth curve, flagging and resampling outliers is repeated until no further outliers are identified.

2. **Deconvolution:** For the time being, the SCC Wastewater $R_t$ model uses the same Richardson Lucy deconvolution algorithm employed by Huisman et al., available through `estimateR`'s `deconvolve_incidence()` function. This algorithm can introduce ringing artifacts, so a future methodological development may be to explore alternative methods. Unlike the original Huisman method, the SCC model does not rescale wastewater inputs based on an assumption that the lowest observed concentration corresponds to one case prior to deconvolution, as in practice we find that rescaling inputs to the deonvolution algorithm by an arbitrary large number generally improves accuracy, while, given proper settings, the absolute number of inferred infections is not relevant to $R_t$ estimation further down the pipeline. For influenza A, we are currently following the lead of [Nadeau et al.](https://doi.org/10.57187/s.3503) in using a shedding load distribution derived from respiratory samples, gamma distributed with mean 2.5 and SD 1, which was derived from the systematic review of [Carrat et al.](https://doi.org/10.1093/aje/kwm375).

3. **Renewal Equation $R_t$ Estimation:** The SCC Wastewater $R_t$ model currently uses the `epiEstim` package's `estimate_R()` function. [`epiEstim`'s method](https://doi.org/10.1093/aje/kwt133) assumes a Poisson renewal process with an analytical Bayesian posterior provided by a gamma conjugate prior on $R_t$ at each timepoint, optionally aggregating incidence over sliding windows to increase posterior precision at the expense of temporal specificity. The SCC model currently adjusts `estimate_R`'s default settings so that the length of the sliding window is set to 1 day, since the smoothing model accounts for short term noise patterns, such as day of week effects, and because confidence intervals are based on bootstrapping rather than `epiEstim`'s Bayesian posterior distribution. The SCC model also adjusts the prior mean value for $R_t$ from 5 to 1, which corresponds to adjusting the default assumption when little information is available in the observed data (e.g., periods with many nondetects or very low concentrations) from assuming very rapid spread, which may be a suitable assumption for introduction of a novel pathogen, to assuming a flat trajectory, which may be more suitable for identifying onsets of new waves of transmission for diseases that are already endemic. The SCC $R_t$ model uses a generation interval based on the work of [Beest et al.](https://doi.org/10.1097/EDE.0b013e31827f50e8) with a mean of 2.6 and SD of $sqrt2.9^1/2 days.

4. **Bootstrap inference:** As in Huisman et al., confidence intervals for $R_t$ are based on 1000 semiparametric bootstrap resamples, in which residuals of normalized wastewater data around the smooth fit are resampled in 10 day blocks, preserving day of the week, then added back to the smoothed point estimate. This method relaxes smooth model assumptions regarding the error distribution, such as homoskedasticity (on the log scale) and independence of errors. After data is resynthesized with the bootstrap residuals, the pipeline is repeated to obtain $R_t$ estimates for each bootstrap iteration, whose 97.5th and 2.5th percentiles are returned to derive a confidence interval, as well as to estimate the odds that the epidemic trajectory (i.e., $R_t ~>~1$ or $R_t ~<~1$) is in the same direction as the point estimate from original data. If the input data contain any censored observations below the limit of detection, an overall empirical error distribution is estimated by combining residuals from non-censored observations with an initial guess for each censored observation based on the expected residual under the fitted smooth model and refined via expectation-maximization by recalculating the expected residual for each censored observation under the empirical error distribution followed by reestimating the empirical error distribution until convergence. The converged empirical error distribution is then used to resample censored residuals during each bootstrap iteration.

5. **Aggregation:** To convert $R_t$ estimates for each sewershed to the overall county estimate, point estimates from the original data, as well as bootstrapped estimates for each sewershed, are combined using a population-weighted average. Inference is then conducted by calculating bootstrap quantiles and odds of agreement of epidemic trajectory with the point estimate based on original data.

**Input data:** Each date's estimate is based on the preceding 6 months of PMMoV-normalized target gene concentrations in wastewater solids provided by [Wastewater SCAN](https://data.wastewaterscan.org/). $R_t$ estimates are currently lagged 8 days prior to the most recent available wastewater data due to delays introduced by the shedding load distribution. Introducing a forecasting / nowcasting component to obtain more recent estimates may be a direction for future development.

## Model change log:

**9-11-2024    v1.0.2**
- By default, model no longer performs linear interpolation of wastewater concentrations prior to smoothing.
- Incorporated an iterative smoothing model selection routine to contend with convergence failures for input series with sparse information. The order of models tried is  
  - Adaptive spline smooth with day of week effects
  - Thin plate spline smooth with day of week effects
  - Adaptive spline smooth with weekday vs. weekend effects
  - Thin plate spline smooth with weekday vs. weekend effects
  - Adaptive spline smooth with no day of week effects
  - Thin plate spline smooth with no day of week effects

**8-21-2024    v1.0.1**
- Model code now accepts full time series of wastewater data in order to derive scale factors for infection incidence and lower limits of detection. This helps to ensure that inferred incidence for lookback periods during which wastewater concentrations were always low are not unrealistically inflated, and may also result in more accurate truncation bounds for censored concentrations, assuming that LLOD is constant over time.
- PMMoV scaling is now handled as an offset during smoothing, which helps resolve realistic truncation bounds for observations below the LLOD. In the prior method, noise added to the target concentration by PMMoV scaling often resulted in unrealistically low LLOD estimates which in turn inflated the variability of smooth fits and often resulted in censored observations being flagged as outliers.
