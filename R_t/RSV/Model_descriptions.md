SCC Wastewater Rt:
==================

## **Model description:** 
The Santa Clara County Wastewater $R_t$ model is derived from the work of [Huisman et al.](https://doi.org/10.1289/EHP10050), but includes several modifications. The model and others like it first fit a smooth curve to the normalized wastewater data to remove noise and recover the underlying trend of interest before converting the wastewater concentrations into an estimated time series of infection events by deconvolving the smoothed wastewater signal with an estimate of the shedding load distribution - i.e., the average quantity of target genes shed over time since infection. Once the time series of infection events has been estimated, $R_t$ can be recovered based on an estimate of the generation interval distribution - i.e., average probability of an infected individual producing secondary infections over time - using standard renewal equation methods. A description of the SCC approach, highlighting unique features, follows:

1. **Smoothing:** Underlying trends in wastewater concentrations are recovered by fitting adaptive splines (`bs = 'ad'` in `mgcv`'s `gam()` function) on the log scale, accounting for day of week effects and AR1 correlation in fitted residuals. Degrees of freedom for the spline basis are estimated at runtime from the historical record of wastewater data by minimizing AIC. If nondetects are present in the data, a Tobit model is fit, which treats these as censored observations somewhere below the lowest observed value, allowing the SCC WW Rt model to acommodate 0 values in its log-transformed wastewater variable. Once the smooth curve has been fit, data are reweighted using a mixture model under which outliers arise from a uniform distribution spanning the range of historically observed values, while non-outliers are distributed according to the conditional log-normal distribution estimated during smoothing (similar in concept to the approach proposed by [Courbariaux et al.](https://doi.org/10.3389/fams.2022.836349)). During this process, if the scale parameter estimated for the lookback period significantly exceeds that estimated for the historical wastewater record, as might happen if nondetects are interspersed with sparse outlying high concentrations, the scale of the smooth model is fixed at the historical value to better differentiate outliers from the bulk of the data.

2. **Deconvolution:** For the time being, the SCC Wastewater $R_t$ model uses the same Richardson Lucy deconvolution algorithm employed by Huisman et al., available through `estimateR`'s `deconvolve_incidence()` function. This algorithm can introduce ringing artifacts, so a future methodological development may be to explore alternative methods. Unlike the original Huisman method, the SCC model does not rescale wastewater inputs based on an assumption that the lowest observed concentration corresponds to one case prior to deconvolution, as in practice we find that rescaling inputs to the deonvolution algorithm by an arbitrary large number generally improves accuracy, while, given proper settings, the absolute number of inferred infections is not relevant to $R_t$ estimation further down the pipeline. For RSV, we are currently using a Gamma shedding load distribution (mean 6.8 days, SD 2.28 days) based on nasopharyngeal swab data collected by [Cohen et al.](https://doi.org/10.1038/s41467-023-44275-y).

3. **Renewal Equation $R_t$ Estimation:** The SCC Wastewater $R_t$ model currently uses the `epiEstim` package's `estimate_R()` function. [`epiEstim`'s method](https://doi.org/10.1093/aje/kwt133) assumes a Poisson renewal process with an analytical Bayesian posterior provided by a gamma conjugate prior on $R_t$ at each timepoint, optionally aggregating incidence over sliding windows to increase posterior precision at the expense of temporal specificity. The SCC model currently adjusts `estimate_R`'s default settings so that the length of the sliding window is set to 1 day, since the smoothing model accounts for short term noise patterns, such as day of week effects, and because confidence intervals are based on bootstrapping rather than `epiEstim`'s Bayesian posterior distribution. The SCC model also adjusts the prior mean value for $R_t$ from 5 to 1, which corresponds to adjusting the default assumption when little information is available in the observed data (e.g., periods with many nondetects or very low concentrations) from assuming very rapid spread, which may be a suitable assumption for introduction of a novel pathogen, to assuming a flat trajectory, which may be more suitable for identifying onsets of new waves of transmission for diseases that are already endemic. The SCC $R_t$ model for RSV uses a generation interval based on [Cohen et al.](https://doi.org/10.1038/s41467-023-44275-y): Gamma distributed with mean 8.4 and SD 4.0 days.

4. **Bootstrap inference:** Confidence intervals for $R_t$ are based on 2000 sieve bootstrap iterations, roughly following methods outlined for time-varying coefficient models by (Friedrich and Lin)[https://doi.org/10.1016/j.jeconom.2022.09.004]. This method accounts for skewness and bias in the bootstrap distribution, as well as autocorrelation in residual errors around the fitted smooth. To begin with, data are oversmoothed with spline degrees of freedom roughly 1/10 of those used for target estimation, then processed through the rest of the pipeline to produce $R_t$ estimates subject to oversmoothing. Residuals from the oversmoothed fit are then used to estimate an autoregressive process for error correlation, incorporating lags up to the maximum at which the PACF has a p-value < 0.1. Within each bootstrap iteration, the decorrelated residuals of this process are then sampled with replacement to generate an innovation time series, autocorrelated errors reconstructed using the parameters of AR process, and the results added back to the oversmoothed predictions to generate a new synthetic time series of wastewater observations, which is re-processed through the estimation pipeline using smoothing with the original degrees of freedom selected via AIC. Quantiles of differences between the resulting bootstrapped $R_t$ estimates and the oversmoothed estimates are then used to construct confidence bands around the original point estimate for $R_t$, as well as to estimate the probability that epidemic trends are in the direction indicated by the point estimate. 

5. **Aggregation:** To convert $R_t$ estimates for each sewershed to the overall county estimate, point estimates from the original data, as well as bootstrapped estimates for each sewershed, are combined using a population-weighted average. Inference is then conducted by calculating bootstrap quantiles and odds of agreement of epidemic trajectory with the point estimate based on original data.

**Input data:** Each date's estimate is based on the preceding 9 months of PMMoV-normalized target gene concentrations in wastewater solids provided by [Wastewater SCAN](https://data.wastewaterscan.org/). $R_t$ estimates are currently lagged 8 days prior to the most recent available wastewater data due to delays introduced by the shedding load distribution. Introducing a forecasting / nowcasting component to obtain more recent estimates may be a direction for future development.


## Model change log:
**1-22-2025    v1.1.1**
- Implemented inference based on sieve bootstrap method, roughly following methods described by (Friedrich and Lin)[https://doi.org/10.1016/j.jeconom.2022.09.004]. 

**1-14-2025    v1.1.0**
- Several adjustments to smoothing method, including:
	- Added routine to estimate basis degrees of freedom from historical wastewater data according to AIC.
	- Switched from adaptive spline basis to thin-plate spline basis with shrinkage (bs = 'ts'). When given the same basis degrees of freedom, this tends to fit run faster and also has the advantage of estimating flat trends for periods when information is sparse
	- Replaced outlier resampling scheme with mixture model routine for downweighting outliers. This reduces randomness in the results and seems to be slightly more robust in terms of reducing outlier influence on smooth estimates
	- Incorporated use of scale parameter estimated from historical data during outlier detection in cases where the scale estimate over the lookback period is statistically significantly higher than that estimated from the historical record. This tends to happen when non-detects are intermingled with sparse outliers, and using the retrospectively informed scale parameter helps differentiate outliers from the bulk of the data
- Refined model run logic
	- Changed lookback period for model runs to 9 months in order to increase the likelihood of having non-zero data on both ends of the period for seasonal diseases
	- Incorporated logic to only run model for sites with at least 4 nonzero observations in the most recent 2 weeks to reduce computational overhead and avoid model runs on excessively sparse data
	- Fixed bug in removal of Rt estimates impacted by left-censoring and removed back-imputation to make it easier to assess archived Rt estimates

**12-19-2024    v1.0.3**
- Added back-imputation during Rt estimation to reduce bias from left-censoring

